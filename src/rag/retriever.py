from typing import List, Dict, Optional
from qdrant_client.models import Filter, FieldCondition, MatchValue

from src.rag.vectordb import VNPTAIVectorDB
from src.etl.embedders import VNPTAIEmbedder


class VNPTAIRetriever:
    """
    RAG Retriever - T√¨m ki·∫øm document chunks relevant v·ªõi user query
    """
    
    def __init__(
        self, 
        collection_name: str = "360_xinchao",
        embedder_model: str = "vnptai_hackathon_embedding"

    ):
        """
        Args:
            collection_name: T√™n collection trong Qdrant
            embedder_model: Model ƒë·ªÉ embed query (ph·∫£i gi·ªëng model khi ingest)
        """
        print("üîß Initializing RAG Retriever...")
        self.db = VNPTAIVectorDB(collection_name=collection_name)
        self.embedder = VNPTAIEmbedder(model_name=embedder_model)
        print("‚úÖ Retriever ready!")
    
    def search(
        self, 
        query: str, 
        top_k: int = 5,
        chunk_type: Optional[str] = None,
        doc_title: Optional[str] = None,
        min_score: float = 0.0
    ) -> List[Dict]:
        """
        T√¨m ki·∫øm chunks relevant v·ªõi query
        
        Args:
            query: C√¢u h·ªèi c·ªßa user (ti·∫øng Vi·ªát)
            top_k: S·ªë l∆∞·ª£ng chunks tr·∫£ v·ªÅ
            chunk_type: L·ªçc theo lo·∫°i chunk ('dieu', 'khoan', 'summary')
            doc_title: L·ªçc theo t√™n vƒÉn b·∫£n c·ª• th·ªÉ
            min_score: Score t·ªëi thi·ªÉu (0-1) ƒë·ªÉ filter k·∫øt qu·∫£
            
        Returns:
            List of dicts ch·ª©a {content, metadata, score}
        """
        print(f"\nüîç Searching for: '{query}'")
        
        # 1. Embed query th√†nh vector
        query_vector = self.embedder.embed([query])[0]
        
        # 2. Build filter n·∫øu c·∫ßn
        search_filter = None
        if chunk_type or doc_title:
            conditions = []
            if chunk_type:
                conditions.append(
                    FieldCondition(key="type", match=MatchValue(value=chunk_type))
                )
            if doc_title:
                conditions.append(
                    FieldCondition(key="doc_title", match=MatchValue(value=doc_title))
                )
            search_filter = Filter(must=conditions)
        
        # 3. Search trong Qdrant
        results = self.db.search(
            query_vector=query_vector, 
            limit=top_k,
            query_filter=search_filter
        )
        
        # 4. Format k·∫øt qu·∫£
        formatted_results = []
        for hit in results:
            # Filter theo min_score
            if hit.score < min_score:
                continue
                
            formatted_results.append({
                'content': hit.payload.get('original_content', ''),  # N·ªôi dung g·ªëc
                'metadata': {
                    'doc_title': hit.payload.get('doc_title'),
                    'source_url': hit.payload.get('source_url'),
                    'type': hit.payload.get('type'),
                    'dieu_so': hit.payload.get('dieu_so'),
                    'khoan_so': hit.payload.get('khoan_so'),
                },
                'score': round(hit.score, 4),
                'id': hit.id
            })
        
        print(f"‚úÖ Found {len(formatted_results)} relevant chunks")
        return formatted_results
    
    def search_with_context(
        self, 
        query: str, 
        top_k: int = 3,
        **kwargs
    ) -> str:
        """
        T√¨m ki·∫øm v√† format th√†nh context cho LLM
        
        Returns:
            String formatted context ready ƒë·ªÉ ƒë∆∞a v√†o LLM prompt
        """
        results = self.search(query, top_k=top_k, **kwargs)
        
        if not results:
            return "Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong c∆° s·ªü d·ªØ li·ªáu."
        
        # Format th√†nh context string
        context_parts = []
        for i, result in enumerate(results, 1):
            meta = result['metadata']
            context_parts.append(
                f"[Ngu·ªìn {i}] {meta['doc_title']}\n"
                f"URL: {meta['source_url']}\n"
                f"{result['content']}\n"
            )
        
        return "\n---\n".join(context_parts)
    
    def get_document_structure(self, doc_title: str) -> Dict:
        """
        L·∫•y c·∫•u tr√∫c c·ªßa m·ªôt vƒÉn b·∫£n c·ª• th·ªÉ (c√°c ƒêi·ªÅu, Kho·∫£n)
        
        Args:
            doc_title: T√™n vƒÉn b·∫£n (v√≠ d·ª•: "Ngh·ªã ƒë·ªãnh 68/2019/Nƒê-CP")
            
        Returns:
            Dict ch·ª©a structure c·ªßa vƒÉn b·∫£n
        """
        # Search summary chunk c·ªßa vƒÉn b·∫£n
        summary = self.search(
            query=doc_title, 
            top_k=1, 
            chunk_type='summary',
            doc_title=doc_title
        )
        
        # Search all ƒëi·ªÅu c·ªßa vƒÉn b·∫£n
        dieu_chunks = self.db.client.scroll(
            collection_name=self.db.collection_name,
            scroll_filter=Filter(
                must=[
                    FieldCondition(key="doc_title", match=MatchValue(value=doc_title)),
                    FieldCondition(key="type", match=MatchValue(value="dieu"))
                ]
            ),
            limit=100
        )
        
        return {
            'summary': summary[0] if summary else None,
            'total_dieu': len(dieu_chunks[0]) if dieu_chunks else 0,
            'dieu_list': [
                f"ƒêi·ªÅu {chunk.payload.get('dieu_so')}" 
                for chunk in (dieu_chunks[0] if dieu_chunks else [])
            ]
        }
