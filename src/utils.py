import yaml
import os
import time
from typing import Optional
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# Determine project root (parent directory of 'src')
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
env_path = os.path.join(project_root, ".env")

# Load .env file if present
load_dotenv(env_path)

from src.crawler.domain_cfg import THU_VIEN_PHAP_LUAT_CFG_MAPPING

def load_llm_config(model_type: str):
    config_path = os.getenv("LLM_CONFIG_PATH")
    if not config_path:
        # Fallback to default config path relative to project_root
        config_path = os.path.join(project_root, "src", "rag", "config", "llm.yaml")
    
    with open(config_path, "r") as f:
        config = yaml.safe_load(f)
    
    # Environment variable overrides for security and flexibility
    prefix_map = {
        "small": "LLM_SMALL",
        "large": "LLM_LARGE",
        "embeddings": "LLM_EMBED"
    }
    
    field_map = {
        "authorization": "AUTH",
        "tokenId": "TOKEN_ID",
        "tokenKey": "TOKEN_KEY",
        "llmApiName": "API_NAME"
    }
    
    if model_type in prefix_map:
        prefix = prefix_map[model_type]
        for config_key, env_suffix in field_map.items():
            env_var = f"{prefix}_{env_suffix}"
            env_val = os.getenv(env_var)
            if env_val:
                if config_key in config['models'][model_type]:
                    config['models'][model_type][config_key] = env_val
            
    return config['models'][model_type]

def load_tvpl_url(domain: str = None, mode='individual'):
    """
    Load url t·ª´ Th∆∞ vi·ªán ph√°p lu·∫≠t
    """
    BASE_URL = "https://thuvienphapluat.vn/van-ban-moi"

    if mode=="individual":
        if domain not in THU_VIEN_PHAP_LUAT_CFG_MAPPING:
            raise ValueError(f"Domain {domain} not found in THU_VIEN_PHAP_LUAT_CFG_MAPPING")
        return BASE_URL, f"{BASE_URL}/{domain}?ft=1"
    if mode == "full":
        urls = []
        for k in THU_VIEN_PHAP_LUAT_CFG_MAPPING.keys():
            urls.append(f"{BASE_URL}/{k}?ft=1")
        return BASE_URL, urls
    raise ValueError("Mode must be 'individual' or 'full'")

def crawl_with_selenium(url, wait_time=5):
    """
    Crawl website v·ªõi Selenium ƒë·ªÉ bypass Cloudflare
    
    Args:
        url: URL c·∫ßn crawl
        wait_time: Th·ªùi gian ch·ªù Cloudflare (gi√¢y), m·∫∑c ƒë·ªãnh 5s
    
    Returns:
        BeautifulSoup object ch·ª©a HTML ƒë√£ ƒë∆∞·ª£c render
    
    Example:
        >>> soup = crawl_with_selenium("https://example.com")
        >>> div = soup.find("div", id="content")
    """
    from selenium import webdriver
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.chrome.options import Options
    
    # ƒê∆∞·ªùng d·∫´n t·ªõi chromedriver local (trong th∆∞ m·ª•c project)
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    chromedriver_path = os.path.join(project_root, "chromedriver-linux64", "chromedriver")
    
    if not os.path.exists(chromedriver_path):
        raise FileNotFoundError(
            f"Chromedriver not found at {chromedriver_path}\n"
            "Please download it from: https://googlechromelabs.github.io/chrome-for-testing/"
        )
    
    # C·∫•u h√¨nh Chrome options
    options = Options()
    options.add_argument("--headless")  # Ch·∫°y ·∫©n
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-blink-features=AutomationControlled")  # ·∫®n automation
    options.add_argument("user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36")
    
    # Kh·ªüi t·∫°o Service v·ªõi chromedriver local
    service = Service(executable_path=chromedriver_path)
    
    # Kh·ªüi t·∫°o driver
    driver = webdriver.Chrome(service=service, options=options)
    
    try:
        print(f"üåê ƒêang truy c·∫≠p: {url}")
        driver.get(url)
        
        # Ch·ªù Cloudflare load xong (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh th·ªùi gian)
        print(f"‚è≥ ƒêang ch·ªù Cloudflare ({wait_time}s)...")
        time.sleep(wait_time)
        
        # L·∫•y HTML sau khi Cloudflare ƒë√£ x·ª≠ l√Ω
        page_source = driver.page_source
        soup = BeautifulSoup(page_source, "html.parser")
        
        print("‚úÖ ƒê√£ l·∫•y ƒë∆∞·ª£c HTML th√†nh c√¥ng!")
        return soup
        
    finally:
        driver.quit()